{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(\"http://localhost:9200/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'node-1', 'cluster_name': 'my-application-cluster', 'cluster_uuid': 'CKjkeoDKR3G-PRs-eQpY9w', 'version': {'number': '8.15.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '98adf7bf6bb69b66ab95b761c9e5aadb0bb059a3', 'build_date': '2024-09-19T10:06:03.564235954Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "print(client.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'fiqa_pl_index' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Define analyzers for Polish text processing\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"polish_with_synonyms\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"morfologik_stem\",\n",
    "                        \"synonym\", # Custom filter for synonyms\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                },\n",
    "                \"polish_without_synonyms\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"morfologik_stem\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"synonym\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"styczeń, sty, I\",\n",
    "                        \"luty, lut, II\",\n",
    "                        \"marzec, mar, III\",\n",
    "                        \"kwiecień, kwi, IV\",\n",
    "                        \"maj, V\",\n",
    "                        \"czerwiec, cze, VI\",\n",
    "                        \"lipiec, lip, VII\",\n",
    "                        \"sierpień, sie, VIII\",\n",
    "                        \"wrzesień, wrz, IX\",\n",
    "                        \"październik, paź, X\",\n",
    "                        \"listopad, lis, XI\",\n",
    "                        \"grudzień, gru, XII\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text_with_synonyms\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"polish_with_synonyms\"\n",
    "            },\n",
    "            \"text_without_synonyms\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"polish_without_synonyms\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"fiqa_pl_index\"\n",
    "\n",
    "if not client.indices.exists(index=index_name):\n",
    "    client.indices.create(index=index_name, body=index_body)\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ds = ds[\"corpus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_data = [\n",
    "    {\n",
    "        \"_index\": index_name,\n",
    "        \"_id\": doc[\"_id\"],\n",
    "        \"_source\": {\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"text_with_synonyms\": doc[\"text\"],\n",
    "            \"text_without_synonyms\": doc[\"text\"]\n",
    "        }\n",
    "    }\n",
    "    for doc in corpus_ds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57638, [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpers.bulk(client, bulk_data) # bulk load the data into the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"kwiecień\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_with_synonyms = client.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text_with_synonyms\": search_term\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "response_without_synonyms = client.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text_without_synonyms\": search_term\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_with_synonyms = response_with_synonyms['hits']['total']['value']\n",
    "num_docs_without_synonyms = response_without_synonyms['hits']['total']['value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents for term kwiecień \n",
      " with synonyms: 307 \n",
      " without synonyms: 258\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents for term {search_term} \\n with synonyms: {num_docs_with_synonyms} \\n without synonyms: {num_docs_without_synonyms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the strengths and weaknesses of regular expressions versus full text search regarding processing of text?\n",
    "\n",
    "##### Strengths of Regular Expressions:\n",
    "1. **Precision:** Allows for exact pattern matching.\n",
    "2. **Flexibility:** Can be tailored for various text formats.\n",
    "3. **Performance:** Faster for small datasets without indexing overhead.\n",
    "\n",
    "#### Weaknesses of Regular Expressions:\n",
    "1. **Complexity:** Difficult to write and maintain for complex patterns.\n",
    "2. **Limited Context Awareness:** Lacks understanding of text semantics.\n",
    "3. **Scalability Issues:** Can become inefficient with large datasets.\n",
    "\n",
    "#### Strengths of Full Text Search:\n",
    "1. **Contextual Understanding:** Incorporates natural language processing for better relevance.\n",
    "2. **Scalability:** Efficiently handles large datasets with indexing.\n",
    "3. **Advanced Features:** Supports stemming, lemmatization, and synonyms.\n",
    "\n",
    "#### Weaknesses of Full Text Search:\n",
    "1. **Less Precision:** May return broader, less relevant results.\n",
    "2. **Overhead:** More complex to set up and maintain.\n",
    "3. **Dependency on Indexing:** Requires re-indexing for frequently changing data.\n",
    "\n",
    "### Can an LLM be applied in the context of searching for documents? Justify your answer, excluding the obvious observation that an LLM can be used to formulate the answer.\n",
    "\n",
    "Yes, LLMs can enhance document searching by:\n",
    "\n",
    "1. **Semantic Search:** Understanding meaning beyond keywords for relevant results.\n",
    "2. **Query Expansion:** Generating synonyms and related terms to improve search.\n",
    "3. **Contextual Relevance:** Ranking results based on context rather than just keywords.\n",
    "4. **Natural Language Interaction:** Allowing users to ask questions in everyday language.\n",
    "5. **Summarization and Extraction:** Providing concise insights from documents.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

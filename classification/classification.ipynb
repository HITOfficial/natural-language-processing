{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import numpy as np\n",
    "from p_tqdm import p_map\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the FIQA-PL dataset that was used in lab 1 and lab lab 2 (so we need the passages, the questions and their relations).\n",
    "\n",
    "Got confiused with FIQA-PL, because indeed it doesn't provide relations between questions and corpus\n",
    "instead used truthful_qa (small english dataset with questions with multiple possible answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['type', 'category', 'question', 'best_answer', 'correct_answers', 'incorrect_answers', 'source'],\n",
       "        num_rows: 817\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"truthfulqa/truthful_qa\", \"generation\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataset of positive and negative sentence pairs.\n",
    "\n",
    "- In each pair the first element is a question and the second element is a passagei, i.e. \"{question} {separator} {passage}\", where separator should be a separator taken from the model's tokenizer.\n",
    "- Use the relations to mark the positive pairs (i.e. pairs where the question is answered by the passage).\n",
    "- Use your own strategy to mark negative pairs (i.e. you can draw the negative examples, but there are better strategies to define the negative examples). The number of negative examples should be larger than the number of positive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs, negative_pairs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separator = tokenizer.sep_token or \"[SEP]\"\n",
    "separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(question, answers):\n",
    "    pairs = []\n",
    "    for answer in answers:\n",
    "        pairs.append(question + ' ' + separator + ' ' + answer)\n",
    "    return pairs\n",
    "\n",
    "positive_pairs = [generate_pairs(q, a) for q, a in zip(ds['validation']['question'], ds['validation']['correct_answers'])]\n",
    "# positive_pairs = p_map(generate_pairs, ds['validation']['question'], ds['validation']['correct_answers']) # p_map is not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  72 mln downloads last month Sentence Transformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def get_top_n_similar_answers(correct_answers, incorrect_answers, candidate_incorrect_answers, top_n=None):\n",
    "\n",
    "    reference_vectors = model.encode(incorrect_answers)\n",
    "    candidate_vectors = model.encode(candidate_incorrect_answers)\n",
    "    \n",
    "    combined_reference_vector = np.mean(reference_vectors, axis=0)\n",
    "    \n",
    "    # cosine similarities between the combined reference vector and all candidate answers\n",
    "    cos_similarities = cosine_similarity([combined_reference_vector], candidate_vectors).flatten()\n",
    "    \n",
    "    # omit correct answers from candidates\n",
    "    filtered_indices = [\n",
    "        idx for idx, candidate in enumerate(candidate_incorrect_answers) \n",
    "        if candidate not in correct_answers\n",
    "    ]\n",
    "\n",
    "    \n",
    "    filtered_similarities = cos_similarities[filtered_indices]\n",
    "    sorted_indices = np.argsort(filtered_similarities)[::-1][:top_n]\n",
    "    \n",
    "    top_n_candidates = [candidate_incorrect_answers[filtered_indices[idx]] for idx in sorted_indices]\n",
    "\n",
    "    return top_n_candidates\n",
    "\n",
    "\n",
    "\n",
    "def generate_incorrect_answers(index):\n",
    "    correct_answers = ds['validation']['correct_answers']\n",
    "    incorrect_answers = ds['validation']['incorrect_answers']\n",
    "    candidate_incorrect_answers = [\n",
    "        incorrect for idx, incorrect in enumerate(incorrect_answers) if idx != index\n",
    "    ]\n",
    "    top_n = 3\n",
    "    # flaten the list of candidate incorrect answers\n",
    "    candidate_incorrect_answers = [item for sublist in candidate_incorrect_answers for item in sublist]\n",
    "    # Get top N most similar incorrect answers\n",
    "    similar_incorrect_answers = get_top_n_similar_answers(\n",
    "        correct_answers[index],\n",
    "        incorrect_answers[index],\n",
    "        candidate_incorrect_answers,\n",
    "        top_n\n",
    "    )\n",
    "    return similar_incorrect_answers + incorrect_answers[index]\n",
    "\n",
    "\n",
    "ds_len = len(ds['validation']['correct_answers'])\n",
    "\n",
    "# new_incorrect_answers = p_map(\n",
    "#     generate_incorrect_answers,\n",
    "#     range(ds_len)\n",
    "# )\n",
    "\n",
    "# p_map stopped working\n",
    "\n",
    "new_incorrect_answers = [\n",
    "    generate_incorrect_answers(i) for i in range(ds_len)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs = [generate_pairs(q, a) for q, a in zip(ds['validation']['question'], new_incorrect_answers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_negative_pairs = [item for sublist in negative_pairs for item in sublist]\n",
    "flatten_positive_pairs = [item for sublist in positive_pairs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive answers 2600 and negative answers 5769\n"
     ]
    }
   ],
   "source": [
    "print(f'positive answers {len(flatten_positive_pairs)} and negative answers {len(flatten_negative_pairs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added three incorrect answers to each questions derived from the incorrect answers of other questions, utilizing cosine similarity to ensure relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset from point 2 should be split into training, evaluation and testing subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = flatten_positive_pairs + flatten_negative_pairs\n",
    "\n",
    "# labels: 1 for positive pairs, 0 for negative pairs\n",
    "labels = [1] * len(flatten_positive_pairs) + [0] * len(flatten_negative_pairs)\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(len(all_pairs))\n",
    "all_pairs = [all_pairs[i] for i in indices]\n",
    "labels = [labels[i] for i in indices]\n",
    "\n",
    "#  split 70% train, 15% eval, 15% test\n",
    "total_size = len(all_pairs)\n",
    "train_size = int(0.7 * total_size)\n",
    "eval_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - eval_size\n",
    "\n",
    "# Dataset: text, label\n",
    "data = {'text': all_pairs, 'label': labels}\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "eval_dataset = dataset.select(range(train_size, train_size + eval_size))\n",
    "test_dataset = dataset.select(range(train_size + eval_size, total_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a text classifier using the Transformers library\n",
    "distinguishes between the positive and the negative pairs. To make the process manageable use models of size base and a runtime providing GPU/TPU acceleration. Consult the discussions related to fine-tuning Transformer models to select sensible set of parameters. You can also run several trainings with different hyper-parameters, if you have access to large computing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model with 60 mln downloads last month\n",
    "model_name = \"bert-base-uncased\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5858/5858 [00:00<00:00, 11272.19 examples/s]\n",
      "Map: 100%|██████████| 1255/1255 [00:00<00:00, 19751.86 examples/s]\n",
      "Map: 100%|██████████| 1256/1256 [00:00<00:00, 21451.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# Apply the tokenizer to the datasets\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "eval_tokenized = eval_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    balanced_accuracy = balanced_accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"balanced_accuracy\": balanced_accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_tokenized, batch_size=16, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_tokenized, batch_size=16)\n",
    "test_dataloader = DataLoader(test_tokenized, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/bochnak/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 367/1101 [02:38<04:43,  2.59it/s]\n",
      " 33%|███▎      | 367/1101 [02:47<04:43,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36286601424217224, 'eval_balanced_accuracy': 0.8037814018520217, 'eval_f1': 0.7450462351387054, 'eval_precision': 0.8269794721407625, 'eval_recall': 0.6778846153846154, 'eval_runtime': 9.7448, 'eval_samples_per_second': 128.787, 'eval_steps_per_second': 8.107, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 500/1101 [03:51<04:25,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.438, 'grad_norm': 7.094197750091553, 'learning_rate': 1.0917347865576748e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 734/1101 [05:35<02:15,  2.71it/s]\n",
      " 67%|██████▋   | 734/1101 [05:45<02:15,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3241387605667114, 'eval_balanced_accuracy': 0.8368593563766389, 'eval_f1': 0.7878787878787878, 'eval_precision': 0.8297872340425532, 'eval_recall': 0.75, 'eval_runtime': 9.9308, 'eval_samples_per_second': 126.375, 'eval_steps_per_second': 7.955, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1000/1101 [07:42<00:41,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2235, 'grad_norm': 1.9304497241973877, 'learning_rate': 1.8346957311534968e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1101/1101 [08:24<00:00,  3.02it/s]\n",
      "100%|██████████| 1101/1101 [08:35<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.338667094707489, 'eval_balanced_accuracy': 0.8470506326212524, 'eval_f1': 0.8020176544766708, 'eval_precision': 0.843501326259947, 'eval_recall': 0.7644230769230769, 'eval_runtime': 9.4084, 'eval_samples_per_second': 133.392, 'eval_steps_per_second': 8.397, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1101/1101 [08:37<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 517.7624, 'train_samples_per_second': 33.942, 'train_steps_per_second': 2.126, 'train_loss': 0.31654600962847607, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1101, training_loss=0.31654600962847607, metrics={'train_runtime': 517.7624, 'train_samples_per_second': 33.942, 'train_steps_per_second': 2.126, 'total_flos': 1155978421724160.0, 'train_loss': 0.31654600962847607, 'epoch': 3.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 60 mln downloads last month model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model='balanced_accuracy',\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,\n",
    "    compute_metrics=compute_metrics\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the results you have obtained for the model. Use appropriate measures, since the dataset is not balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:09<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.29952314496040344, 'eval_balanced_accuracy': 0.86421603223924, 'eval_f1': 0.811554332874828, 'eval_precision': 0.8240223463687151, 'eval_recall': 0.7994579945799458, 'eval_runtime': 9.3531, 'eval_samples_per_second': 134.287, 'eval_steps_per_second': 8.446, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:09<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "Balanced Accuracy: 0.8642\n",
      "F1 Score: 0.8116\n",
      "Precision: 0.8240\n",
      "Recall: 0.7995\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results = trainer.evaluate(test_tokenized)\n",
    "\n",
    "print(\"Test Results:\", test_results)\n",
    "\n",
    "test_predictions = trainer.predict(test_tokenized)\n",
    "\n",
    "test_metrics = compute_metrics(test_predictions)\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "print(f\"Balanced Accuracy: {test_metrics['balanced_accuracy']:.4f}\")\n",
    "print(f\"F1 Score: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "\n",
    "true_labels = test_predictions.label_ids\n",
    "predicted_labels = np.argmax(test_predictions.predictions, axis=1)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained Model score for balanced accuracy is 0.87 which is quite good result, especially for not the easiest dataset with more than twice as many wrong answers (2600 positive labels vs 5679 negative labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the classifier as a re-ranker for finding the answers to the questions.\n",
    "Since the re-ranker is slow, you have to limit the subset of possible passages to top-n (10, 50 or 100 - depending on your GPU) texts returned by much faster model, e.g. FTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute how much the result of searching the passages improved over the results from lab 2. Use NDCG to compare the results.\n",
    "\n",
    "Used different model so gonna just calculate NDCG of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(scores, k):\n",
    "    scores = scores[:k]\n",
    "    return sum(score / np.log2(idx + 2) for idx, score in enumerate(scores))\n",
    "\n",
    "# nDCG@k\n",
    "def ndcg_at_k(relevance_scores, k=10):\n",
    "    ideal_scores = sorted(relevance_scores, reverse=True)\n",
    "    dcg = dcg_at_k(relevance_scores, k)\n",
    "    idcg = dcg_at_k(ideal_scores, k)\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: Do you think simpler methods, like Bayesian bag-of-words model, would work for sentence-pair classification? Justify your answer.\n",
    "\n",
    "Simpler methods like a Bayesian bag-of-words model can be effective, they often fail to capture the contextual relationships. In my approach, I used cosine similarity with the Sentence Transformer model (`all-MiniLM-L6-v2`), which encodes sentences into dense vectors, allowing for effective semantic comparison. This model's popularity (72 million downloads last month) highlights its effectiveness in understanding context, making it superior for this task.\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 2: What hyper-parameters did you select for training? What resources did you consult?\n",
    "\n",
    "I selected the following hyper-parameters for training:\n",
    "- Learning Rate: 2e-5\n",
    "- Batch Size: 16\n",
    "- Number of Epochs: 3\n",
    "- Weight Decay: 0.01\n",
    "- Evaluation Strategy: Evaluate at the end of each epoch\n",
    "- Load best model at the end\n",
    "\n",
    "These were chosen based on insights from Hugging Face documentation.\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 3: What are the pros and cons of neural network models in NLP?\n",
    "\n",
    "**Pros:**\n",
    "1. Contextual Understanding: Neural networks capture contextual relationships, improving performance in tasks like sentence-pair classification.\n",
    "2. Transfer Learning: Pre-trained models can be fine-tuned on specific tasks, leveraging knowledge from large datasets.\n",
    "\n",
    "**Cons:**\n",
    "1. Resource Intensive: Large models require significant computational resources, which can be a barrier for smaller projects.\n",
    "2. Overfitting Risk: The complexity of neural networks can lead to overfitting, necessitating careful regularization and validation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

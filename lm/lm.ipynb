{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bochnak/anaconda3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForCausalLM, pipeline\n",
    "from transformers.models.bert import BertForMaskedLM\n",
    "from transformers.models.gpt2 import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download three Polish models from the Huggingface repository.\n",
    "These should be regular language models, which were not fine-tuned. E.g. HerBERT and papuGaPT2 are good examples. You can also try using Bielik for that, but make sure you are using the model via Transformers API, not GUI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"HerBERT\": {\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\"),\n",
    "        \"model\": AutoModelForMaskedLM.from_pretrained(\"allegro/herbert-base-cased\"),\n",
    "        \"pipeline\": None,\n",
    "    },\n",
    "    \"papuGaPT2\": {\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained(\"flax-community/papuGaPT2\"),\n",
    "        \"model\": AutoModelForCausalLM.from_pretrained(\"flax-community/papuGaPT2\"),\n",
    "        \"pipeline\": None,\n",
    "    },\n",
    "    \"Bielik\": {\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\"),\n",
    "        \"model\": AutoModelForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\"),\n",
    "        \"pipeline\": None,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Devise a method to test if the langage model understands Polish cases.\n",
    " E.g. testing for nominal case could be expressed as \"Warszawa to największe [MASK]\", and the masked word should be in nominative case. Create sentences for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline (fill-mask) successfully assigned for model: HerBERT\n",
      "Pipeline (text-generation) successfully assigned for model: papuGaPT2\n",
      "Pipeline (fill-mask) successfully assigned for model: Bielik\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_info in models.items():\n",
    "    model = model_info[\"model\"]\n",
    "\n",
    "    if isinstance(model, BertForMaskedLM):\n",
    "        fill_mask_pipeline = pipeline(\"fill-mask\", model=model, tokenizer=model_info[\"tokenizer\"])\n",
    "        models[model_name][\"pipeline\"] = fill_mask_pipeline\n",
    "        print(f\"Pipeline (fill-mask) successfully assigned for model: {model_name}\")\n",
    "\n",
    "    elif isinstance(model, GPT2LMHeadModel):\n",
    "        text_generation_pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=model_info[\"tokenizer\"],\n",
    "            max_new_tokens=2,\n",
    "            pad_token_id=model_info[\"tokenizer\"].eos_token_id,\n",
    "            eos_token_id=model_info[\"tokenizer\"].eos_token_id,\n",
    "            top_k=50,\n",
    "            top_p=0.9\n",
    "        )\n",
    "        models[model_name][\"pipeline\"] = text_generation_pipeline\n",
    "        print(f\"Pipeline (text-generation) successfully assigned for model: {model_name}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Model {model_name} is not compatible with the intended pipelines.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing cases with HerBERT model:\n",
      "\n",
      "Case: nominative\n",
      "Prediction: Warszawa to największe miasto . (Score: 0.8103939294815063)\n",
      "Prediction: Warszawa to największe lotnisko . (Score: 0.08249125629663467)\n",
      "Prediction: Warszawa to największe centrum . (Score: 0.026521336287260056)\n",
      "\n",
      "Case: genitive\n",
      "Prediction: To ciężkie zadanie , potrzebuję trochę więcej czasu . (Score: 0.4029397666454315)\n",
      "Prediction: To ciężkie zadanie , potrzebuję trochę więcej cierpliwości . (Score: 0.11514861136674881)\n",
      "Prediction: To ciężkie zadanie , potrzebuję trochę więcej doświadczenia . (Score: 0.09145424515008926)\n",
      "\n",
      "Case: dative\n",
      "Prediction: Mój pies Zeus przyglądał się temu . (Score: 0.3961878716945648)\n",
      "Prediction: Mój pies Zeus przyglądał się wszystkiemu . (Score: 0.13475088775157928)\n",
      "Prediction: Mój pies Zeus przyglądał się mu . (Score: 0.05179081857204437)\n",
      "\n",
      "Case: accusative\n",
      "Prediction: Wczoraj w stawie widziałem dużą burzę . (Score: 0.1044120118021965)\n",
      "Prediction: Wczoraj w stawie widziałem dużą rzekę . (Score: 0.0810621902346611)\n",
      "Prediction: Wczoraj w stawie widziałem dużą dziurę . (Score: 0.06021549180150032)\n",
      "\n",
      "Case: instrumental\n",
      "Prediction: Wczoraj podróżowałem z moim synem . (Score: 0.21374928951263428)\n",
      "Prediction: Wczoraj podróżowałem z moim mężem . (Score: 0.13855023682117462)\n",
      "Prediction: Wczoraj podróżowałem z moim kolegą . (Score: 0.07405316829681396)\n",
      "\n",
      "Case: locative\n",
      "Prediction: Wczoraj po wywiadówce z moją mamą rozmawialiśmy o moich planach . (Score: 0.29985353350639343)\n",
      "Prediction: Wczoraj po wywiadówce z moją mamą rozmawialiśmy o moich dzieciach . (Score: 0.1757470667362213)\n",
      "Prediction: Wczoraj po wywiadówce z moją mamą rozmawialiśmy o moich problemach . (Score: 0.13204386830329895)\n",
      "\n",
      "Testing cases with papuGaPT2 model:\n",
      "\n",
      "Case: nominative\n",
      "Prediction: Warszawa to największe ród na\n",
      "\n",
      "Case: genitive\n",
      "Prediction: To ciężkie zadanie, potrzebuję trochę więcej ）\n",
      "\n",
      "Case: dative\n",
      "Prediction: Mój pies Zeus przyglądał się łowaczom\n",
      "\n",
      "Case: accusative\n",
      "Prediction: Wczoraj w stawie widziałem dużą rójkę\n",
      "\n",
      "Case: instrumental\n",
      "Prediction: Wczoraj podróżowałem z moim nemka\n",
      "\n",
      "Case: locative\n",
      "Prediction: Wczoraj po wywiadówce z moją mamą rozmawialiśmy o moich łowach\n",
      "\n",
      "Testing cases with Bielik model:\n",
      "\n",
      "Case: nominative\n",
      "Prediction: Warszawa to największe miasto. (Score: 0.9553059935569763)\n",
      "Prediction: Warszawa to największe województwo. (Score: 0.0065080937929451466)\n",
      "Prediction: Warszawa to największe lotnisko. (Score: 0.005074796266853809)\n",
      "\n",
      "Case: genitive\n",
      "Prediction: To ciężkie zadanie, potrzebuję trochę więcej czasu. (Score: 0.6750841736793518)\n",
      "Prediction: To ciężkie zadanie, potrzebuję trochę więcej pracy. (Score: 0.020163556560873985)\n",
      "Prediction: To ciężkie zadanie, potrzebuję trochę więcej pieniędzy. (Score: 0.018410973250865936)\n",
      "\n",
      "Case: dative\n",
      "Prediction: Mój pies Zeus przyglądał się temu. (Score: 0.16015353798866272)\n",
      "Prediction: Mój pies Zeus przyglądał się tobie. (Score: 0.07319647818803787)\n",
      "Prediction: Mój pies Zeus przyglądał się jej. (Score: 0.0676044449210167)\n",
      "\n",
      "Case: accusative\n",
      "Prediction: Wczoraj w stawie widziałem dużą rybę. (Score: 0.7800177335739136)\n",
      "Prediction: Wczoraj w stawie widziałem dużą dziewczynkę. (Score: 0.017225343734025955)\n",
      "Prediction: Wczoraj w stawie widziałem dużą rzecz. (Score: 0.011612358503043652)\n",
      "\n",
      "Case: instrumental\n",
      "Prediction: Wczoraj podróżowałem z moim ojcem. (Score: 0.32932519912719727)\n",
      "Prediction: Wczoraj podróżowałem z moim mężem. (Score: 0.1357676386833191)\n",
      "Prediction: Wczoraj podróżowałem z moim bratem. (Score: 0.09200859814882278)\n",
      "\n",
      "Case: locative\n",
      "Prediction: Wczoraj po wywiadówce z moją mamą rozmawialiśmy o moich dzieciach. (Score: 0.2987850606441498)\n",
      "Prediction: Wczoraj po wywiadówce z moją mamą rozmawialiśmy o moich problemach. (Score: 0.14421924948692322)\n",
      "Prediction: Wczoraj po wywiadówce z moją mamą rozmawialiśmy o moich planach. (Score: 0.07317749410867691)\n"
     ]
    }
   ],
   "source": [
    "masks = {\n",
    "    \"HerBERT\": \"<mask>.\",\n",
    "    \"Bielik\": \"[MASK].\",\n",
    "    \"papuGaPT2\" : \"\"\n",
    "}\n",
    "\n",
    "case_sentences = {\n",
    "    \"nominative\": \"Warszawa to największe {mask}\",\n",
    "    \"genitive\": \"To ciężkie zadanie, potrzebuję trochę więcej {mask}\",\n",
    "    \"dative\": \"Mój pies Zeus przyglądał się {mask}\",\n",
    "    \"accusative\": \"Wczoraj w stawie widziałem dużą {mask}\",\n",
    "    \"instrumental\": \"Wczoraj podróżowałem z moim {mask}\",\n",
    "    \"locative\": \"Wczoraj po wywiadówce z moją mamą rozmawialiśmy o moich {mask}\",\n",
    "}\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    if model_info[\"pipeline\"]:\n",
    "        print(f\"\\nTesting cases with {model_name} model:\")\n",
    "\n",
    "        mask = masks.get(model_name, \"<mask>\")\n",
    "\n",
    "        for case, sentence in case_sentences.items():\n",
    "            sentence_with_mask = sentence.format(mask=mask)\n",
    "            print(f\"\\nCase: {case}\")\n",
    "            outputs = model_info[\"pipeline\"](sentence_with_mask)\n",
    "            if model_name in [\"HerBERT\", \"Bielik\"]:\n",
    "                for output in outputs[:3]:\n",
    "                    print(f\"Prediction: {output['sequence']} (Score: {output['score']})\")\n",
    "            elif model_name == \"papuGaPT2\":\n",
    "                for output in outputs[:3]:\n",
    "                    print(f\"Prediction: {output['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Devise a method to test long-range relationships such as gender.\n",
    "E.e. you can use two verbs with masculine and feminine gender, where one of the verbs is masked. Both verbs should have the same gender, assuming the subject is the same. Define at least 3 such sentences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing gender relationships with HerBERT model:\n",
      "Prediction: Maria jest świetną lekarką i zawsze dokładnie słucha swoich pacjentów , zanim ich leczy . (Score: 0.2329351007938385)\n",
      "Prediction: Maria jest świetną lekarką i zawsze dokładnie słucha swoich pacjentów , zanim ich odwiedzi . (Score: 0.1360275000333786)\n",
      "Prediction: Maria jest świetną lekarką i zawsze dokładnie słucha swoich pacjentów , zanim ich postawi . (Score: 0.13440170884132385)\n",
      "Prediction: Andrzej spędził dużo czasu nad zadaniami zanim wszystkie je wykonał . (Score: 0.38248470425605774)\n",
      "Prediction: Andrzej spędził dużo czasu nad zadaniami zanim wszystkie je rozwiązał . (Score: 0.10732978582382202)\n",
      "Prediction: Andrzej spędził dużo czasu nad zadaniami zanim wszystkie je ukończył . (Score: 0.09674196690320969)\n",
      "Prediction: Agnieszka była zmęczona , ale pomimo to dalej żyła . (Score: 0.16098259389400482)\n",
      "Prediction: Agnieszka była zmęczona , ale pomimo to dalej walczyła . (Score: 0.14678335189819336)\n",
      "Prediction: Agnieszka była zmęczona , ale pomimo to dalej pracowała . (Score: 0.124876007437706)\n",
      "\n",
      "Testing gender relationships with papuGaPT2 model:\n",
      "Prediction: Maria jest świetną lekarką i zawsze dokładnie słucha swoich pacjentów, zanim ich laryngolog\n",
      "Prediction: Andrzej spędził dużo czasu nad zadaniami zanim wszystkie je owiązał\n",
      "Prediction: Agnieszka była zmęczona, ale pomimo to dalej łowała\n",
      "\n",
      "Testing gender relationships with Bielik model:\n",
      "Prediction: Maria jest świetną lekarką i zawsze dokładnie słucha swoich pacjentów, zanim ich zobaczy. (Score: 0.21240124106407166)\n",
      "Prediction: Maria jest świetną lekarką i zawsze dokładnie słucha swoich pacjentów, zanim ich pozna. (Score: 0.08333886414766312)\n",
      "Prediction: Maria jest świetną lekarką i zawsze dokładnie słucha swoich pacjentów, zanim ich zabije. (Score: 0.04203284904360771)\n",
      "Prediction: Andrzej spędził dużo czasu nad zadaniami zanim wszystkie je wykonał. (Score: 0.234587162733078)\n",
      "Prediction: Andrzej spędził dużo czasu nad zadaniami zanim wszystkie je rozwiązał. (Score: 0.05233663320541382)\n",
      "Prediction: Andrzej spędził dużo czasu nad zadaniami zanim wszystkie je ukończył. (Score: 0.04892021417617798)\n",
      "Prediction: Agnieszka była zmęczona, ale pomimo to dalej żyła. (Score: 0.2349366545677185)\n",
      "Prediction: Agnieszka była zmęczona, ale pomimo to dalej spała. (Score: 0.10330387949943542)\n",
      "Prediction: Agnieszka była zmęczona, ale pomimo to dalej pracowała. (Score: 0.08858872950077057)\n"
     ]
    }
   ],
   "source": [
    "gender_sentences = [\n",
    "    \"Maria jest świetną lekarką i zawsze dokładnie słucha swoich pacjentów, zanim ich {mask}\",\n",
    "    \"Andrzej spędził dużo czasu nad zadaniami zanim wszystkie je {mask}\",\n",
    "    \"Agnieszka była zmęczona, ale pomimo to dalej {mask}\",\n",
    "]\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    if model_info[\"pipeline\"]:\n",
    "        mask = masks.get(model_name, \"<mask>\")\n",
    "        print(f\"\\nTesting gender relationships with {model_name} model:\")\n",
    "        for sentence in gender_sentences:\n",
    "            sentence_with_mask = sentence.format(mask=mask)\n",
    "            outputs = model_info[\"pipeline\"](sentence_with_mask)\n",
    "            if model_name in [\"HerBERT\", \"Bielik\"]:\n",
    "                for output in outputs[:3]:  # Display top 3 predictions\n",
    "                    print(f\"Prediction: {output['sequence']} (Score: {output['score']})\")\n",
    "            elif model_name == \"papuGaPT2\":\n",
    "                for output in outputs[:3]:  # Display top 3 predictions\n",
    "                    print(f\"Prediction: {output['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the model captures real-world knolwedge. For instance a sentence \"[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\"\n",
    " checks if the model \"knows\" the description of water. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing real-world knowledge with HerBERT model:\n",
      "Prediction: Stolicą Polski jest Warszawa . (Score: 0.609553337097168)\n",
      "Prediction: Stolicą Polski jest Kraków . (Score: 0.0991559699177742)\n",
      "Prediction: Stolicą Polski jest Gdańsk . (Score: 0.08018141239881516)\n",
      "Prediction: Najwyższą górą Polski są Niemcy . (Score: 0.5421215891838074)\n",
      "Prediction: Najwyższą górą Polski są Polacy . (Score: 0.07686690241098404)\n",
      "Prediction: Najwyższą górą Polski są Austriacy . (Score: 0.040299177169799805)\n",
      "Prediction: Najlepszy w historii piłkarz z Argentyny to . . (Score: 0.1165275052189827)\n",
      "Prediction: Najlepszy w historii piłkarz z Argentyny to Francuz . (Score: 0.02994181029498577)\n",
      "Prediction: Najlepszy w historii piłkarz z Argentyny to Polak . (Score: 0.025129610672593117)\n",
      "Prediction: Stolicą Niemiec jest Berlin . (Score: 0.693077564239502)\n",
      "Prediction: Stolicą Niemiec jest Monachium . (Score: 0.16482771933078766)\n",
      "Prediction: Stolicą Niemiec jest Stuttgart . (Score: 0.1128314808011055)\n",
      "Prediction: Stolicą Francji jest Paryż . (Score: 0.7776497602462769)\n",
      "Prediction: Stolicą Francji jest Lyon . (Score: 0.13299959897994995)\n",
      "Prediction: Stolicą Francji jest Bordeaux . (Score: 0.04730105400085449)\n",
      "Prediction: 2 wojnę światową rozpoczęli Niemcy . (Score: 0.7175590991973877)\n",
      "Prediction: 2 wojnę światową rozpoczęli Rosjanie . (Score: 0.06640005111694336)\n",
      "Prediction: 2 wojnę światową rozpoczęli Francuzi . (Score: 0.05092622712254524)\n",
      "Prediction: 2 wojnę światową wygrali Niemcy . (Score: 0.7991869449615479)\n",
      "Prediction: 2 wojnę światową wygrali Francuzi . (Score: 0.05936354771256447)\n",
      "Prediction: 2 wojnę światową wygrali Brytyjczycy . (Score: 0.02893192321062088)\n",
      "\n",
      "Testing real-world knowledge with papuGaPT2 model:\n",
      "Prediction: Stolicą Polski jest łęczyca\n",
      "Prediction: Najwyższą górą Polski są owiane\n",
      "Prediction: Najlepszy w historii piłkarz z Argentyny to ..........\n",
      "Prediction: Stolicą Niemiec jest ród Han\n",
      "Prediction: Stolicą Francji jest éle\n",
      "Prediction: 2 wojnę światową rozpoczęli owcy i\n",
      "Prediction: 2 wojnę światową wygrali ną w\n",
      "\n",
      "Testing real-world knowledge with Bielik model:\n",
      "Prediction: Stolicą Polski jest Warszawa. (Score: 0.24870306253433228)\n",
      "Prediction: Stolicą Polski jest Gdańsk. (Score: 0.06255218386650085)\n",
      "Prediction: Stolicą Polski jest Polska. (Score: 0.046921856701374054)\n",
      "Prediction: Najwyższą górą Polski są Niemcy. (Score: 0.27051886916160583)\n",
      "Prediction: Najwyższą górą Polski są Czechy. (Score: 0.1246902197599411)\n",
      "Prediction: Najwyższą górą Polski są Węgry. (Score: 0.10346551984548569)\n",
      "Prediction: Najlepszy w historii piłkarz z Argentyny to Manuel. (Score: 0.02935340628027916)\n",
      "Prediction: Najlepszy w historii piłkarz z Argentyny to Urugwaj. (Score: 0.019614826887845993)\n",
      "Prediction: Najlepszy w historii piłkarz z Argentyny to Lorenzo. (Score: 0.0193090308457613)\n",
      "Prediction: Stolicą Niemiec jest Polska. (Score: 0.08196217566728592)\n",
      "Prediction: Stolicą Niemiec jest Warszawa. (Score: 0.06454018503427505)\n",
      "Prediction: Stolicą Niemiec jest Berlin. (Score: 0.05627024546265602)\n",
      "Prediction: Stolicą Francji jest Paryż. (Score: 0.35811126232147217)\n",
      "Prediction: Stolicą Francji jest Francja. (Score: 0.09537323564291)\n",
      "Prediction: Stolicą Francji jest Belgia. (Score: 0.05163960158824921)\n",
      "Prediction: 2 wojnę światową rozpoczęli Niemcy. (Score: 0.3324713408946991)\n",
      "Prediction: 2 wojnę światową rozpoczęli Rosjanie. (Score: 0.16044853627681732)\n",
      "Prediction: 2 wojnę światową rozpoczęli Polacy. (Score: 0.12566083669662476)\n",
      "Prediction: 2 wojnę światową wygrali Niemcy. (Score: 0.23802441358566284)\n",
      "Prediction: 2 wojnę światową wygrali Rosjanie. (Score: 0.22466044127941132)\n",
      "Prediction: 2 wojnę światową wygrali Polacy. (Score: 0.10382978618144989)\n"
     ]
    }
   ],
   "source": [
    "knowledge_sentences = [\n",
    "    \"Stolicą Polski jest {mask}\",\n",
    "    \"Najwyższą górą Polski są {mask}\",\n",
    "    \"Najlepszy w historii piłkarz z Argentyny to {mask}\",\n",
    "    \"Stolicą Niemiec jest {mask}\",\n",
    "    \"Stolicą Francji jest {mask}\",\n",
    "    \"2 wojnę światową rozpoczęli {mask}\",\n",
    "    \"2 wojnę światową wygrali {mask}\"\n",
    "]\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    if model_info[\"pipeline\"]:\n",
    "        mask = masks.get(model_name, \"<mask>\")\n",
    "        print(f\"\\nTesting real-world knowledge with {model_name} model:\")\n",
    "        for sentence in knowledge_sentences:\n",
    "            sentence_with_mask = sentence.format(mask=mask)\n",
    "            outputs = model_info[\"pipeline\"](sentence_with_mask)\n",
    "            if model_name in [\"HerBERT\", \"Bielik\"]:\n",
    "                for output in outputs[:3]:  # Display top 3 predictions\n",
    "                    print(f\"Prediction: {output['sequence']} (Score: {output['score']})\")\n",
    "            elif model_name == \"papuGaPT2\":\n",
    "                for output in outputs[:3]:  # Display top 3 predictions\n",
    "                    print(f\"Prediction: {output['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check zero-shot learning capabilites of the models.\n",
    "Provide at least 5 sentences with different sentiment for the following scheme: \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie [MASK]\" Try different prompts, to see if they make any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing zero-shot sentiment analysis with HerBERT model:\n",
      "Prediction: ' Ten film był super . Nie mogłem się oderwać od ekranu . ' Wypowiedź ta jest zdecydowanie prawdziwa . (Score: 0.19030681252479553)\n",
      "Prediction: ' Ten film był super . Nie mogłem się oderwać od ekranu . ' Wypowiedź ta jest zdecydowanie słuszna . (Score: 0.13067613542079926)\n",
      "Prediction: ' Ten film był super . Nie mogłem się oderwać od ekranu . ' Wypowiedź ta jest zdecydowanie najlepsza . (Score: 0.12920497357845306)\n",
      "Prediction: ' To był bardzo nudny film , ledwo dotrwałem do końca . ' Wypowiedź ta jest zdecydowanie prawdziwa . (Score: 0.2557086944580078)\n",
      "Prediction: ' To był bardzo nudny film , ledwo dotrwałem do końca . ' Wypowiedź ta jest zdecydowanie słuszna . (Score: 0.1446705013513565)\n",
      "Prediction: ' To był bardzo nudny film , ledwo dotrwałem do końca . ' Wypowiedź ta jest zdecydowanie zła . (Score: 0.08947570621967316)\n",
      "Prediction: ' Jestem zadowolony z tego zakupu , jakość jest świetna ! ' Wypowiedź ta jest zdecydowanie pozytywna . (Score: 0.24957124888896942)\n",
      "Prediction: ' Jestem zadowolony z tego zakupu , jakość jest świetna ! ' Wypowiedź ta jest zdecydowanie słuszna . (Score: 0.17930330336093903)\n",
      "Prediction: ' Jestem zadowolony z tego zakupu , jakość jest świetna ! ' Wypowiedź ta jest zdecydowanie prawdziwa . (Score: 0.13994872570037842)\n",
      "Prediction: ' Nie polecam tego produktu , zawiodłem się . ' Wypowiedź ta jest zdecydowanie prawdziwa . (Score: 0.2596680223941803)\n",
      "Prediction: ' Nie polecam tego produktu , zawiodłem się . ' Wypowiedź ta jest zdecydowanie słuszna . (Score: 0.25680145621299744)\n",
      "Prediction: ' Nie polecam tego produktu , zawiodłem się . ' Wypowiedź ta jest zdecydowanie uzasadniona . (Score: 0.07874782383441925)\n",
      "Prediction: ' Książka była ciekawa , i bardzo mnie wciągnęła . ' Wypowiedź ta jest zdecydowanie prawdziwa . (Score: 0.23178239166736603)\n",
      "Prediction: ' Książka była ciekawa , i bardzo mnie wciągnęła . ' Wypowiedź ta jest zdecydowanie pozytywna . (Score: 0.1011609360575676)\n",
      "Prediction: ' Książka była ciekawa , i bardzo mnie wciągnęła . ' Wypowiedź ta jest zdecydowanie słuszna . (Score: 0.09467945992946625)\n",
      "\n",
      "Testing zero-shot sentiment analysis with papuGaPT2 model:\n",
      "Prediction: 'Ten film był super. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie owiana\n",
      "Prediction: 'To był bardzo nudny film, ledwo dotrwałem do końca.' Wypowiedź ta jest zdecydowanie owiana\n",
      "Prediction: 'Jestem zadowolony z tego zakupu, jakość jest świetna!' Wypowiedź ta jest zdecydowanie .............\n",
      "Prediction: 'Nie polecam tego produktu, zawiodłem się.' Wypowiedź ta jest zdecydowanie owiana\n",
      "Prediction: 'Książka była ciekawa, i bardzo mnie wciągnęła.' Wypowiedź ta jest zdecydowanie owiana\n",
      "\n",
      "Testing zero-shot sentiment analysis with Bielik model:\n",
      "Prediction: ' Ten film był super. Nie mogłem się oderwać od ekranu.'Wypowiedź ta jest zdecydowanie lepsza. (Score: 0.1264953315258026)\n",
      "Prediction: ' Ten film był super. Nie mogłem się oderwać od ekranu.'Wypowiedź ta jest zdecydowanie najlepsza. (Score: 0.09742730855941772)\n",
      "Prediction: ' Ten film był super. Nie mogłem się oderwać od ekranu.'Wypowiedź ta jest zdecydowanie najgorsza. (Score: 0.08607684820890427)\n",
      "Prediction: ' To był bardzo nudny film, ledwo dotrwałem do końca.'Wypowiedź ta jest zdecydowanie lepsza. (Score: 0.1888660341501236)\n",
      "Prediction: ' To był bardzo nudny film, ledwo dotrwałem do końca.'Wypowiedź ta jest zdecydowanie najlepsza. (Score: 0.07572013884782791)\n",
      "Prediction: ' To był bardzo nudny film, ledwo dotrwałem do końca.'Wypowiedź ta jest zdecydowanie inna. (Score: 0.0637279748916626)\n",
      "Prediction: ' Jestem zadowolony z tego zakupu, jakość jest świetna!'Wypowiedź ta jest zdecydowanie lepsza. (Score: 0.35129478573799133)\n",
      "Prediction: ' Jestem zadowolony z tego zakupu, jakość jest świetna!'Wypowiedź ta jest zdecydowanie inna. (Score: 0.07824987173080444)\n",
      "Prediction: ' Jestem zadowolony z tego zakupu, jakość jest świetna!'Wypowiedź ta jest zdecydowanie najlepsza. (Score: 0.051519155502319336)\n",
      "Prediction: ' Nie polecam tego produktu, zawiodłem się.'Wypowiedź ta jest zdecydowanie lepsza. (Score: 0.23802347481250763)\n",
      "Prediction: ' Nie polecam tego produktu, zawiodłem się.'Wypowiedź ta jest zdecydowanie inna. (Score: 0.10677909851074219)\n",
      "Prediction: ' Nie polecam tego produktu, zawiodłem się.'Wypowiedź ta jest zdecydowanie gorsza. (Score: 0.05601195991039276)\n",
      "Prediction: ' Książka była ciekawa, i bardzo mnie wciągnęła.'Wypowiedź ta jest zdecydowanie lepsza. (Score: 0.17026804387569427)\n",
      "Prediction: ' Książka była ciekawa, i bardzo mnie wciągnęła.'Wypowiedź ta jest zdecydowanie prawdziwa. (Score: 0.06813622266054153)\n",
      "Prediction: ' Książka była ciekawa, i bardzo mnie wciągnęła.'Wypowiedź ta jest zdecydowanie najlepsza. (Score: 0.06650715321302414)\n"
     ]
    }
   ],
   "source": [
    "sentiment_sentences = [\n",
    "    \"'Ten film był super. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie {mask}\",\n",
    "    \"'To był bardzo nudny film, ledwo dotrwałem do końca.' Wypowiedź ta jest zdecydowanie {mask}\",\n",
    "    \"'Jestem zadowolony z tego zakupu, jakość jest świetna!' Wypowiedź ta jest zdecydowanie {mask}\",\n",
    "    \"'Nie polecam tego produktu, zawiodłem się.' Wypowiedź ta jest zdecydowanie {mask}\",\n",
    "    \"'Książka była ciekawa, i bardzo mnie wciągnęła.' Wypowiedź ta jest zdecydowanie {mask}\",\n",
    "]\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    if model_info[\"pipeline\"]:\n",
    "        mask = masks.get(model_name, \"<mask>\")\n",
    "        print(f\"\\nTesting zero-shot sentiment analysis with {model_name} model:\")\n",
    "        for sentence in sentiment_sentences:\n",
    "            sentence_with_mask = sentence.format(mask=mask)\n",
    "            outputs = model_info[\"pipeline\"](sentence_with_mask)\n",
    "            if model_name in [\"HerBERT\", \"Bielik\"]:\n",
    "                for output in outputs[:3]:  # Display top 3 predictions\n",
    "                    print(f\"Prediction: {output['sequence']} (Score: {output['score']})\")\n",
    "            elif model_name == \"papuGaPT2\":\n",
    "                for output in outputs[:3]:  # Display top 3 predictions\n",
    "                    print(f\"Prediction: {output['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the following questions (2 points):\n",
    "\n",
    "1. Which of the models produced the best results?\n",
    "\n",
    "The best results were produced by the masked language models, HerBERT and Bielik. Overall, Bielik’s responses were closer to the expected answers.\n",
    "\n",
    "2. Was any of the models able to capture Polish grammar?\n",
    "\n",
    "Both masked language models handled Polish grammar well, providing grammatically correct responses in each case. However, the responses from the causal language model were often incorrect.\n",
    "\n",
    "3. Was any of the models able to capture long-distant relationships between the words?\n",
    "\n",
    "Both masked language models captured long-distance relationships between words. However it should be clear from the context that the word the model predicts should be used in that specific gender.\n",
    "\n",
    "4. Was any of the models able to capture world knowledge?\n",
    "\n",
    "Partially. Both models were able to predict some world knowledge, such as country capitals and certain historical facts. However, they struggled with popular knowledge, like identifying Argentina’s most famous football player or specific geographic data.\n",
    "\n",
    "5. Was any of the models good at doing zero-shot classification?\n",
    "\n",
    "No, neither model was precise in zero-shot classification. The predictions in each case were similar, making them difficult to distinguish.\n",
    "\n",
    "6. What are the most striking errors made by the models?\n",
    "\n",
    "The most striking errors were made by the causal language model. Its responses did not fit the context of the sentences. Since the GPT-2 architecture was not designed for masked language modeling, it struggled with filling masked tokens accurately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
